{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9f43525",
   "metadata": {},
   "source": [
    "# Assignment 9 - Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a6d009",
   "metadata": {},
   "source": [
    "## Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ace0fb",
   "metadata": {},
   "source": [
    "### Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04397965",
   "metadata": {},
   "source": [
    "- **What type of algorithm did we use in exercise 1?**\n",
    "\n",
    "For exercise one we use the AgglomerativeClustering algoritm which is the \"bottom-up\" algoritm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04499b7",
   "metadata": {},
   "source": [
    "- **How many types of hierarchical clustering are you familiar with?**\n",
    "\n",
    "Currently i am familiar with the Agglomerative and the Divisible algoritms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e06c61",
   "metadata": {},
   "source": [
    "- **How do they differ?**\n",
    "\n",
    "So as before mentioned, the agglomerative uses the \"bottom-up\" approach, meaning that each point starts out as its own cluster, and from there, we cluster these together depending on how close they are to each other, to make bigger clusters.\n",
    "The other one is the divisible algoritm which is the opposite, and starts with only one cluster which is the whole dataset, and divides these into smaller and smaller clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2b369e",
   "metadata": {},
   "source": [
    "### Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cc6905b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cluster import  MeanShift, estimate_bandwidth\n",
    "\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "import seaborn as sns\n",
    "import plotly.express as pxp\n",
    "import plotly.graph_objs as gph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5fad83a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(193, 48)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>1972</th>\n",
       "      <th>1973</th>\n",
       "      <th>1974</th>\n",
       "      <th>1975</th>\n",
       "      <th>1976</th>\n",
       "      <th>1977</th>\n",
       "      <th>1978</th>\n",
       "      <th>1979</th>\n",
       "      <th>1980</th>\n",
       "      <th>...</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       country  1972  1973  1974  1975  1976  1977  1978  1979  1980  ...  \\\n",
       "0  Afghanistan   4.5   6.5   6.5   6.5   6.5   6.0   7.0   7.0   7.0  ...   \n",
       "1      Albania   7.0   7.0   7.0   7.0   7.0   7.0   7.0   7.0   7.0  ...   \n",
       "2      Algeria   6.0   6.0   6.0   6.5   6.0   6.0   6.0   6.0   6.0  ...   \n",
       "3      Andorra   3.5   4.0   4.0   4.0   4.0   NaN   NaN   NaN   NaN  ...   \n",
       "4       Angola   NaN   NaN   NaN   6.0   6.0   7.0   7.0   7.0   7.0  ...   \n",
       "\n",
       "   2009  2010  2011  2012  2013  2014  2015  2016  2017  2018  \n",
       "0   6.0   6.0   6.0   6.0   6.0   6.0   6.0   6.0   5.5   5.5  \n",
       "1   3.0   3.0   3.0   3.0   3.0   3.0   3.0   3.0   3.0   3.0  \n",
       "2   5.5   5.5   5.5   5.5   5.5   5.5   5.5   5.5   5.5   5.5  \n",
       "3   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0  \n",
       "4   5.5   5.5   5.5   5.5   5.5   5.5   6.0   6.0   6.0   5.5  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"soft2022spring-DS/Data/freedom.csv\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b5ca8300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 193 entries, 0 to 192\n",
      "Data columns (total 48 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   country  193 non-null    object \n",
      " 1   1972     142 non-null    float64\n",
      " 2   1973     143 non-null    float64\n",
      " 3   1974     145 non-null    float64\n",
      " 4   1975     151 non-null    float64\n",
      " 5   1976     152 non-null    float64\n",
      " 6   1977     148 non-null    float64\n",
      " 7   1978     151 non-null    float64\n",
      " 8   1979     154 non-null    float64\n",
      " 9   1980     155 non-null    float64\n",
      " 10  1981     157 non-null    float64\n",
      " 11  1982     0 non-null      float64\n",
      " 12  1983     158 non-null    float64\n",
      " 13  1984     159 non-null    float64\n",
      " 14  1985     159 non-null    float64\n",
      " 15  1986     159 non-null    float64\n",
      " 16  1987     159 non-null    float64\n",
      " 17  1988     159 non-null    float64\n",
      " 18  1989     160 non-null    float64\n",
      " 19  1990     160 non-null    float64\n",
      " 20  1991     179 non-null    float64\n",
      " 21  1992     183 non-null    float64\n",
      " 22  1993     188 non-null    float64\n",
      " 23  1994     189 non-null    float64\n",
      " 24  1995     189 non-null    float64\n",
      " 25  1996     189 non-null    float64\n",
      " 26  1997     189 non-null    float64\n",
      " 27  1998     189 non-null    float64\n",
      " 28  1999     190 non-null    float64\n",
      " 29  2000     190 non-null    float64\n",
      " 30  2001     190 non-null    float64\n",
      " 31  2002     190 non-null    float64\n",
      " 32  2003     190 non-null    float64\n",
      " 33  2004     190 non-null    float64\n",
      " 34  2005     190 non-null    float64\n",
      " 35  2006     192 non-null    float64\n",
      " 36  2007     192 non-null    float64\n",
      " 37  2008     192 non-null    float64\n",
      " 38  2009     192 non-null    float64\n",
      " 39  2010     192 non-null    float64\n",
      " 40  2011     193 non-null    float64\n",
      " 41  2012     193 non-null    float64\n",
      " 42  2013     193 non-null    float64\n",
      " 43  2014     193 non-null    float64\n",
      " 44  2015     193 non-null    float64\n",
      " 45  2016     193 non-null    float64\n",
      " 46  2017     193 non-null    float64\n",
      " 47  2018     193 non-null    float64\n",
      "dtypes: float64(47), object(1)\n",
      "memory usage: 72.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c04f736",
   "metadata": {},
   "source": [
    "#### Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f8af45df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mathias\\AppData\\Local\\Temp/ipykernel_8624/3021921920.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  column_means = df.mean()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "country      0\n",
       "1972         0\n",
       "1973         0\n",
       "1974         0\n",
       "1975         0\n",
       "1976         0\n",
       "1977         0\n",
       "1978         0\n",
       "1979         0\n",
       "1980         0\n",
       "1981         0\n",
       "1982       193\n",
       "1983         0\n",
       "1984         0\n",
       "1985         0\n",
       "1986         0\n",
       "1987         0\n",
       "1988         0\n",
       "1989         0\n",
       "1990         0\n",
       "1991         0\n",
       "1992         0\n",
       "1993         0\n",
       "1994         0\n",
       "1995         0\n",
       "1996         0\n",
       "1997         0\n",
       "1998         0\n",
       "1999         0\n",
       "2000         0\n",
       "2001         0\n",
       "2002         0\n",
       "2003         0\n",
       "2004         0\n",
       "2005         0\n",
       "2006         0\n",
       "2007         0\n",
       "2008         0\n",
       "2009         0\n",
       "2010         0\n",
       "2011         0\n",
       "2012         0\n",
       "2013         0\n",
       "2014         0\n",
       "2015         0\n",
       "2016         0\n",
       "2017         0\n",
       "2018         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_means = df.mean()\n",
    "df = df.fillna(column_means)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "58e6f19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = df.iloc[:, -1:].values\n",
    "X2 = df.iloc[:, 1:2].values\n",
    "X = np.concatenate((X1,X2), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feae1ecc",
   "metadata": {},
   "source": [
    "#### Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d85a9b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bandwidth is found automatically with\n",
    "bandwidth = estimate_bandwidth(X, quantile=0.2, n_samples=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "95907c80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train mean-shift model with the data frame\n",
    "msmodel = MeanShift(bandwidth=bandwidth, bin_seeding=True)\n",
    "msmodel.fit(X)\n",
    "labels = msmodel.labels_\n",
    "labels_unique = np.unique(labels)\n",
    "n_clusters_ = len(labels_unique)\n",
    "n_clusters_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "abf6e0cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.07246377, 4.5460298 ],\n",
       "       [6.0754717 , 5.71306139],\n",
       "       [1.5125    , 1.7125    ]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the clusters and cluster centres\n",
    "cluster_centers = msmodel.cluster_centers_\n",
    "cluster_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "246b5972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1, 0, 0, 0, 2, 2, 1, 0, 1, 1, 2, 1, 2, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 1, 1, 2, 0, 1, 1, 2, 1, 2, 0, 1, 1, 2, 1, 0, 1,\n",
       "       2, 0, 2, 1, 0, 2, 0, 1, 2, 1, 1, 0, 1, 1, 2, 2, 2, 1, 2, 0, 0, 0,\n",
       "       0, 0, 2, 1, 1, 2, 1, 0, 0, 2, 2, 0, 1, 1, 2, 2, 2, 2, 2, 1, 1, 0,\n",
       "       0, 1, 1, 1, 0, 2, 0, 0, 1, 2, 0, 2, 0, 0, 2, 1, 1, 2, 0, 1, 2, 0,\n",
       "       0, 0, 2, 0, 0, 1, 0, 1, 0, 2, 0, 2, 2, 1, 1, 0, 1, 0, 2, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 2, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 2, 0, 0, 0, 1, 0, 2, 2, 1, 1, 1, 1, 0, 1, 2, 2,\n",
       "       0, 1, 1, 0, 1, 0, 1, 2, 2, 0, 1, 0, 1, 1, 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict the cluster for all the samples\n",
    "Y = msmodel.predict(X)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "faf5e3cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(msmodel.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "38e64b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1, 0, 0, 0, 2, 2, 1, 0, 1, 1, 2, 1, 2, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 1, 1, 2, 0, 1, 1, 2, 1, 2, 0, 1, 1, 2, 1, 0, 1,\n",
       "       2, 0, 2, 1, 0, 2, 0, 1, 2, 1, 1, 0, 1, 1, 2, 2, 2, 1, 2, 0, 0, 0,\n",
       "       0, 0, 2, 1, 1, 2, 1, 0, 0, 2, 2, 0, 1, 1, 2, 2, 2, 2, 2, 1, 1, 0,\n",
       "       0, 1, 1, 1, 0, 2, 0, 0, 1, 2, 0, 2, 0, 0, 2, 1, 1, 2, 0, 1, 2, 0,\n",
       "       0, 0, 2, 0, 0, 1, 0, 1, 0, 2, 0, 2, 2, 1, 1, 0, 1, 0, 2, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 2, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 2, 0, 0, 0, 1, 0, 2, 2, 1, 1, 1, 1, 0, 1, 2, 2,\n",
       "       0, 1, 1, 0, 1, 0, 1, 2, 2, 0, 1, 0, 1, 1, 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict the cluster for all the samples\n",
    "P = msmodel.predict(X)\n",
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a1c4c87b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deploy/msmodelAS9.pkl']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For serialization and deserialization of data from/to file\n",
    "# from sklearn.externals import joblib\n",
    "import joblib\n",
    "joblib.dump(msmodel, 'deploy/msmodelAS9.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4157c162",
   "metadata": {},
   "source": [
    "This would have deployed the model in a file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0089c7ab",
   "metadata": {},
   "source": [
    "#### Task is continued in \"Assignment 9 part 2\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
